---
title: "machine learning barbell prediction"
output: html_document
---
##Introduction

This is to predict manner of activity using the data generated by sensors. A big training data set is used to train a model. Firstly useless or incomplete variables are depleted, resultin in a new dataset, which is then preprocessed by centering and scaling. The preprocessed data is partitioned into training dataset and testing dataset. Then k-fold cross validation is used to resample the training dataset and calculate the out of sample errors. Based on the out of sample errors, a best modeling method is selected out of several models.The out of sample error is calculated eithor based on cross validation resampling or by using the testing dataset, and the results are similar as expected. At last, the 20 test cases are preprocessed and the unknown manners associated are predicted using the selected model.

### Data importation and preprocessing.
Import train and test data, and preprocess by removing variables with too many NAs. Also center and scale the variables.

```{r Import Data, cache=TRUE, message=FALSE, echo=TRUE}

traindata_raw<-read.csv('pml-training.csv', na.strings=c("","NA"), stringsAsFactors=FALSE)
testdata_raw<-read.csv('pml-testing.csv',na.strings=c("","NA"))
#remove variables containing too many NAs 
NAnumbers<-apply(traindata_raw, 2, function(x) {sum(is.na(x))})
library('dplyr')
library('caret')
traindata_pp<-dplyr::select(traindata_raw, which(NAnumbers==0))
traindata_pp<-select(traindata_pp, -c(X, user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window, num_window))
traindata_pp$classe<-as.factor(traindata_pp$classe)
#center and scale the variables
centerscale<-preProcess(dplyr::select(traindata_pp,-classe), method=c("center", "scale"))
transformed<-predict(centerscale, dplyr::select(traindata_pp,-classe))
traindata_prepro<-data.frame(transformed, classe=traindata_pp$classe)

```

### Data partition.
Generate training dataset and testing data for validation from the train dataset.

```{r use_caret_preprocess, cache=TRUE, message=FALSE, echo=TRUE}

set.seed(125)
trainIndex = createDataPartition(traindata_prepro$classe, p = 0.70, list=FALSE)

training = traindata_prepro[trainIndex,]

testing = traindata_prepro[-trainIndex,]

```

### Compare different models. 
Compare different models using crossvalidation. To save computation time, use k fold cross validation without repeat. K is set to be 3 to save computation time. GBM, SVM, rf and LDA models will be tested.

```{r train models, cache=TRUE, message=FALSE, echo=TRUE, results='hide'}
control<-trainControl(method="cv", number=3) #set the cross validation
set.seed(150)
mdlgbm<-train(classe~., data=training, method="gbm", trControl=control)
set.seed(150)
mdllda<-train(classe~., data=training, method="lda", trControl=control)
set.seed(150)
mdlsvm<-train(classe~., data=training, method="svmRadial", trControl=control)
set.seed(150)
mdlrf<-train(classe~., data=training, method="rf", trControl=control)
```
The performance of the different models is summarized below:
```{r summaryresults, cache=TRUE, message=FALSE, echo=TRUE}
mdlresult<-resamples(list(gbm=mdlgbm, lda=mdllda, svm=mdlsvm, rf=mdlrf))
summary(mdlresult)
bwplot(mdlresult)
```
We can see that rf model and GBM mmodel are better than the others. Choose rf model, because its accuracy is the best among the four mtheods.  The averaged out of sample error calculated by 3-fold cross validation is `r 1-mean(mdlrf$resample$Accuracy)`. 

### Out of sample errors again.
The testing dataset can be used to calculate the out of sample errors again. Use the rf model.

```{r, cache=TRUE, message=FALSE, echo=TRUE}
predres<-predict(mdlrf, newdata=testing)
testingerror<-1-sum(predres==testing$classe)/length(testing$classe)
```
As expected, the out of sample error calculated from the testing dataset is `r testingerror`, very close to the mean value evaluated by crossvalidation of the training dataset.

### Predict the 20 cases.
Predict the unknown classe of the 20 cases using the rf model.

```{r predict unknown classe, cache=TRUE, message=FALSE, echo=TRUE}
varname<-colnames(training)
varname<-varname[-which(varname %in% "classe")]
testdata_pp<-testdata_raw[,varname]
testdata_prepro<-predict(centerscale, testdata_pp)
predict_result<-predict(mdlrf, newdata=testdata_prepro)

```
The predicted results are: `r predict_result`.